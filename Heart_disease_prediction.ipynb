{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd43c5fa-e41a-48fa-ba30-0526d5677d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e9d74b-3b64-4739-a054-76a69c2e7329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets_4123_6408_framingham.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8897aa78-8133-49fc-8748-018b35f676be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79800ddc-665e-4108-b010-8a84b87acbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf076c9-6ff4-4220-b940-e06a896d1a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6699bb-c673-417c-b523-56db42a78c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8496dace-d319-4302-86cb-3a6ff391de38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4240, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde910a7-3df7-4818-91df-559bb21332a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43c96fde-79ef-4919-a565-a3b175c9f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the binary columns\n",
    "bin_cols = [\"male\", \"currentSmoker\", \"prevalentStroke\", \"prevalentHyp\", \"diabetes\"]\n",
    "\n",
    "# Fill missing values for binary features with the most frequent value (mode)\n",
    "for col in bin_cols:\n",
    "    mode_val = df[col].mode()[0]\n",
    "    df[col].fillna(mode_val, inplace=True)\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14568a81-e010-4981-bf5c-f1bea55bf904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "# Fill missing values for numeric features\n",
    "numeric_cols = [\"cigsPerDay\", \"BPMeds\", \"totChol\", \"BMI\", \"heartRate\", \"glucose\"]\n",
    "for col in numeric_cols:\n",
    "    median_val = df[col].median()\n",
    "    df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "\n",
    "# Check if there are any remaining missing values\n",
    "missing_values = df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4eb1af1-d74d-4cc1-8abc-19ccfa2e750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c381046-579f-4417-8fe3-861615f09738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenYearCHD\n",
       "0    3596\n",
       "1     644\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TenYearCHD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0521b31-281e-4322-b6b7-6ef65efa40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['TenYearCHD'] == 0]\n",
    "df_minority = df[df['TenYearCHD'] == 1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # Sample with replacement\n",
    "                                 n_samples=len(df_majority),    # To match majority class\n",
    "                                 random_state=42) # Reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47d947ad-7a2f-4b51-8e76-4fb3a83cb9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TenYearCHD\n",
       "0    3596\n",
       "1    3596\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['TenYearCHD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d48d46-e4e1-4aed-9042-380a013be9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test split and feature scaling  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0d62e1f-9e0b-4076-89fa-2673926623e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df_balanced.drop(columns=['TenYearCHD'])\n",
    "y = df_balanced['TenYearCHD']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b02cac4-65c9-48fa-81cf-23a549a520bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling (StandardScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "796c24a2-9bb4-4401-a6c1-a67e7cf306a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler to training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dab851ff-a4eb-4ad8-b653-c2f56cc4ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 10 models with different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dce93c58-c0e0-42df-a535-998f2078a96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Accuracy: 0.9735927727588604\n",
      "Classification Report for RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       735\n",
      "           1       0.95      0.99      0.97       704\n",
      "\n",
      "    accuracy                           0.97      1439\n",
      "   macro avg       0.97      0.97      0.97      1439\n",
      "weighted avg       0.97      0.97      0.97      1439\n",
      "\n",
      "Confusion Matrix for RandomForestClassifier:\n",
      "[[702  33]\n",
      " [  5 699]]\n",
      "==================================================\n",
      "AdaBoostClassifier Accuracy: 0.6719944405837387\n",
      "Classification Report for AdaBoostClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67       735\n",
      "           1       0.66      0.68      0.67       704\n",
      "\n",
      "    accuracy                           0.67      1439\n",
      "   macro avg       0.67      0.67      0.67      1439\n",
      "weighted avg       0.67      0.67      0.67      1439\n",
      "\n",
      "Confusion Matrix for AdaBoostClassifier:\n",
      "[[486 249]\n",
      " [223 481]]\n",
      "==================================================\n",
      "GradientBoostingClassifier Accuracy: 0.7289784572619875\n",
      "Classification Report for GradientBoostingClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72       735\n",
      "           1       0.70      0.77      0.74       704\n",
      "\n",
      "    accuracy                           0.73      1439\n",
      "   macro avg       0.73      0.73      0.73      1439\n",
      "weighted avg       0.73      0.73      0.73      1439\n",
      "\n",
      "Confusion Matrix for GradientBoostingClassifier:\n",
      "[[508 227]\n",
      " [163 541]]\n",
      "==================================================\n",
      "LogisticRegression Accuracy: 0.6587908269631688\n",
      "Classification Report for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       735\n",
      "           1       0.65      0.66      0.66       704\n",
      "\n",
      "    accuracy                           0.66      1439\n",
      "   macro avg       0.66      0.66      0.66      1439\n",
      "weighted avg       0.66      0.66      0.66      1439\n",
      "\n",
      "Confusion Matrix for LogisticRegression:\n",
      "[[481 254]\n",
      " [237 467]]\n",
      "==================================================\n",
      "SVC Accuracy: 0.6831132731063239\n",
      "Classification Report for SVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.67      0.68       735\n",
      "           1       0.67      0.70      0.68       704\n",
      "\n",
      "    accuracy                           0.68      1439\n",
      "   macro avg       0.68      0.68      0.68      1439\n",
      "weighted avg       0.68      0.68      0.68      1439\n",
      "\n",
      "Confusion Matrix for SVC:\n",
      "[[493 242]\n",
      " [214 490]]\n",
      "==================================================\n",
      "KNeighborsClassifier Accuracy: 0.7873523280055594\n",
      "Classification Report for KNeighborsClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76       735\n",
      "           1       0.72      0.92      0.81       704\n",
      "\n",
      "    accuracy                           0.79      1439\n",
      "   macro avg       0.81      0.79      0.78      1439\n",
      "weighted avg       0.81      0.79      0.78      1439\n",
      "\n",
      "Confusion Matrix for KNeighborsClassifier:\n",
      "[[482 253]\n",
      " [ 53 651]]\n",
      "==================================================\n",
      "DecisionTreeClassifier Accuracy: 0.9179986101459346\n",
      "Classification Report for DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91       735\n",
      "           1       0.86      1.00      0.92       704\n",
      "\n",
      "    accuracy                           0.92      1439\n",
      "   macro avg       0.93      0.92      0.92      1439\n",
      "weighted avg       0.93      0.92      0.92      1439\n",
      "\n",
      "Confusion Matrix for DecisionTreeClassifier:\n",
      "[[620 115]\n",
      " [  3 701]]\n",
      "==================================================\n",
      "GaussianNB Accuracy: 0.5830437804030577\n",
      "Classification Report for GaussianNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.91      0.69       735\n",
      "           1       0.72      0.24      0.36       704\n",
      "\n",
      "    accuracy                           0.58      1439\n",
      "   macro avg       0.64      0.58      0.53      1439\n",
      "weighted avg       0.64      0.58      0.53      1439\n",
      "\n",
      "Confusion Matrix for GaussianNB:\n",
      "[[668  67]\n",
      " [533 171]]\n",
      "==================================================\n",
      "XGBClassifier Accuracy: 0.906184850590688\n",
      "Classification Report for XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       735\n",
      "           1       0.86      0.96      0.91       704\n",
      "\n",
      "    accuracy                           0.91      1439\n",
      "   macro avg       0.91      0.91      0.91      1439\n",
      "weighted avg       0.91      0.91      0.91      1439\n",
      "\n",
      "Confusion Matrix for XGBClassifier:\n",
      "[[625 110]\n",
      " [ 25 679]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define a list of classifiers\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{clf_name} Accuracy: {accuracy}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"Classification Report for {clf_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(f\"Confusion Matrix for {clf_name}:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c11ec331-71c6-464d-a710-a2de38475e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results table for each model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09e47b25-da49-47c0-8c31-7a5454cd12c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23256\\1329335574.py:42: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame({'Model': [clf_name],\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.974288</td>\n",
       "      <td>0.974289</td>\n",
       "      <td>0.974977</td>\n",
       "      <td>0.974288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.671994</td>\n",
       "      <td>0.672015</td>\n",
       "      <td>0.672474</td>\n",
       "      <td>0.671994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.728978</td>\n",
       "      <td>0.728702</td>\n",
       "      <td>0.731320</td>\n",
       "      <td>0.728978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.658791</td>\n",
       "      <td>0.658830</td>\n",
       "      <td>0.659053</td>\n",
       "      <td>0.658791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.683113</td>\n",
       "      <td>0.683126</td>\n",
       "      <td>0.683656</td>\n",
       "      <td>0.683113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.787352</td>\n",
       "      <td>0.783833</td>\n",
       "      <td>0.812481</td>\n",
       "      <td>0.787352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.914524</td>\n",
       "      <td>0.914107</td>\n",
       "      <td>0.926013</td>\n",
       "      <td>0.914524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.583044</td>\n",
       "      <td>0.530092</td>\n",
       "      <td>0.635597</td>\n",
       "      <td>0.583044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.906185</td>\n",
       "      <td>0.905977</td>\n",
       "      <td>0.912148</td>\n",
       "      <td>0.906185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Accuracy  F1-Score  Precision    Recall\n",
       "0      RandomForestClassifier  0.974288  0.974289   0.974977  0.974288\n",
       "1          AdaBoostClassifier  0.671994  0.672015   0.672474  0.671994\n",
       "2  GradientBoostingClassifier  0.728978  0.728702   0.731320  0.728978\n",
       "3          LogisticRegression  0.658791  0.658830   0.659053  0.658791\n",
       "4                         SVC  0.683113  0.683126   0.683656  0.683113\n",
       "5        KNeighborsClassifier  0.787352  0.783833   0.812481  0.787352\n",
       "6      DecisionTreeClassifier  0.914524  0.914107   0.926013  0.914524\n",
       "7                  GaussianNB  0.583044  0.530092   0.635597  0.583044\n",
       "8               XGBClassifier  0.906185  0.905977   0.912148  0.906185"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define a list of classifiers\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB(),\n",
    "    XGBClassifier()\n",
    "]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'F1-Score', 'Precision', 'Recall'])\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    \n",
    "    # Append results to DataFrame\n",
    "    # Append results to DataFrame\n",
    "    results_df = pd.concat([results_df, pd.DataFrame({'Model': [clf_name], \n",
    "                                                  'Accuracy': [accuracy], \n",
    "                                                  'F1-Score': [f1_score], \n",
    "                                                  'Precision': [precision], \n",
    "                                                  'Recall': [recall]})], ignore_index=True)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bef0196d-a9e7-4fe3-84eb-e6071d9f032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc4edb36-91eb-4fe4-a8ff-e262881f142d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.9728978457261988\n",
      "Classification Report for Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       735\n",
      "           1       0.95      0.99      0.97       704\n",
      "\n",
      "    accuracy                           0.97      1439\n",
      "   macro avg       0.97      0.97      0.97      1439\n",
      "weighted avg       0.97      0.97      0.97      1439\n",
      "\n",
      "Confusion Matrix for Random Forest Classifier:\n",
      "[[701  34]\n",
      " [  5 699]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Instantiate the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classifier Accuracy:\", accuracy_rf)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report for Random Forest Classifier:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix for Random Forest Classifier:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2967fb25-abc2-4089-bb4f-487a48ef300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6515b464-23f3-480b-8d53-1619d0d03e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  0\n",
      "actual class  0\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca7e673a-c67b-44ae-8c7d-057673bafe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  1\n",
      "actual class  1\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[200].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "190e5b0f-7ea4-480d-a068-27ddbe16d0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predcted class  1\n",
      "actual class  1\n"
     ]
    }
   ],
   "source": [
    "# test 3:\n",
    "print(\"predcted class \",rf_classifier.predict(X_test_scaled[110].reshape(1,-1))[0])\n",
    "print(\"actual class \", y_test.iloc[110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67339302-f3b5-436a-be77-2c7024e0a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd58b66e-d0d8-422c-8193-14d9426e8deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rf_classifier,open(\"rf_classifier.pkl\",'wb'))\n",
    "pickle.dump(scaler,open(\"scaler.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3af4d54-a9d7-4d93-a0b7-29087dfcacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model to test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47c415ce-d726-41a6-b34b-8b02530022c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RandomForestClassifier model\n",
    "with open(\"rf_classifier.pkl\", \"rb\") as file:\n",
    "    rf_classifier = pickle.load(file)\n",
    "\n",
    "# Load the scaler\n",
    "with open(\"scaler.pkl\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08e2cc82-3ab3-48f9-9795-8ebc5bbacda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21a781e6-94dc-4435-9148-295046bbb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(model, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose):\n",
    "    # Encode categorical variables\n",
    "    male_encoded = 1 if male.lower() == \"male\" else 0\n",
    "    currentSmoker_encoded = 1 if currentSmoker.lower() == \"yes\" else 0\n",
    "    BPMeds_encoded = 1 if BPMeds.lower() == \"yes\" else 0\n",
    "    prevalentStroke_encoded = 1 if prevalentStroke.lower() == \"yes\" else 0\n",
    "    prevalentHyp_encoded = 1 if prevalentHyp.lower() == \"yes\" else 0\n",
    "    diabetes_encoded = 1 if diabetes.lower() == \"yes\" else 0\n",
    "    \n",
    "    # Prepare features array\n",
    "    features = np.array([[male_encoded, age, currentSmoker_encoded, cigsPerDay, BPMeds_encoded, prevalentStroke_encoded, prevalentHyp_encoded, diabetes_encoded, totChol, sysBP, diaBP, BMI, heartRate, glucose]])\n",
    "    \n",
    "    # scalling\n",
    "    scaled_features = scaler.transform(features)\n",
    "    \n",
    "    # predict by model\n",
    "    result = model.predict(scaled_features)\n",
    "    \n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c8e57c1-ad81-42cf-9898-71516c45e09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DON'T WORRY !! The Patiennt has No Heart Disease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# test 1:\n",
    "male = \"female\"\n",
    "age = 56.00\n",
    "currentSmoker = \"yes\"\n",
    "cigsPerDay = 3.00\n",
    "BPMeds = \"no\"\n",
    "prevalentStroke = \"no\"\n",
    "prevalentHyp = \"yes\"\n",
    "diabetes = 'no'\n",
    "totChol = 285.00\n",
    "sysBP = 145.00\n",
    "diaBP = 100.00\n",
    "BMI = 30.14\n",
    "heartRate = 80.00\n",
    "glucose = 86.00\n",
    "\n",
    "\n",
    "result = predict(rf_classifier, scaler, male, age, currentSmoker, cigsPerDay, BPMeds, prevalentStroke, prevalentHyp, diabetes, totChol, sysBP, diaBP, BMI, heartRate, glucose)\n",
    "\n",
    "\n",
    "if result == 1:\n",
    "    print(\"The Patient has Heart Disease\")\n",
    "else: \n",
    "    print(\"DON'T WORRY !! The Patiennt has No Heart Disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da89bf8-4199-44ee-bb7a-a60fc1bcff6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import sklearn\n",
    "sklearn.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
